{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule-based Classification\n",
    "- builds and an fp-tree-like structure to compress data\n",
    "- mine the rules from the tree by using an algorithm that was based on class squential rule mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "\n",
    "import math\n",
    "import pandas\n",
    "import numpy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------\n",
    "### Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`transformed_data.csv` file contains the training set and testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_random_sampling_data():\n",
    "    \"\"\"\n",
    "    Reads the data in the csv file and convert it into pandas dataframe.\n",
    "    This returns the training and testing set.\n",
    "    \"\"\"\n",
    "    file = os.path.abspath('../files/transformed_data.csv')\n",
    "    data_frame = pandas.read_csv(file)\n",
    "    training = []\n",
    "    testing = []\n",
    "    \n",
    "    # convert to list\n",
    "    for column in data_frame:\n",
    "        list_ = data_frame.loc[:, column].values.tolist()\n",
    "        for item in list_:\n",
    "            # For filtering out the Nan values\n",
    "            if isinstance(item, str):\n",
    "                string_array = item.split(',')\n",
    "            \n",
    "                if column == 'training':\n",
    "                    training.append(string_array)\n",
    "                elif column == 'testing':\n",
    "                    testing.append(string_array)\n",
    "            \n",
    "                string_array = []\n",
    "                \n",
    "    return training, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_training, raw_testing = load_random_sampling_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create the tree, the inputs should be a dictionary with the itemsets as the dictionary keys and its frequency as the value. The **create_initial_set()** converts the dataset into a python ordered dictionary.\n",
    "\n",
    "This also eliminates duplicates in the dataset. This returns all the unique patterns in the dataset and the number of time the pattern occured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_initial_set(dataset):\n",
    "    \"\"\"the createTree() function doesn't take the input data as lists. \n",
    "    It expects a dictionary with the itemsets as the dictionary keys \n",
    "    and the frequency as the value. A createInitSet() function does \n",
    "    this conversion for you.\"\"\"\n",
    "\n",
    "    dictionary = OrderedDict()\n",
    "\n",
    "    for transaction in dataset:\n",
    "        pattern = tuple(transaction)\n",
    "        \n",
    "        if pattern in dictionary.keys():\n",
    "            dictionary[pattern] += 1\n",
    "        else:\n",
    "            dictionary[pattern] = 1\n",
    "            \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_set = create_initial_set(raw_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the original implementation of the FP-growth, the second step rearrange the items per transaction according to a list. Let's denote this list or set as **ordered item set**. The **ordered item set** contains the unique items in the database with their corresponding **support count** (the number of times they apper in the database) and is sorted in a desceding order based on the **support count**. But beacause in this case our item set consist of a group of items (the example below will further explain this point), we will tweak the algorithm a little bit. Our **ordered item set** will contain the category names instead.\n",
    "\n",
    "Example:\n",
    "`(('saan', 'pr', 'rb', 'nn', 'cc', 'nn', 'abbreviation'), 1)`\n",
    "\n",
    "In the transaction above, `('saan', 'pr', 'rb', 'nn', 'cc', 'nn', 'abbreviation')` is the item, not the individual member of the pattern which are `saan`, `pr`, `rb` and soon.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_frequent_item_set(item_set):\n",
    "    \"\"\"\n",
    "    Sort the frequent item set in descending order according to their support count.\n",
    "    \n",
    "    item_set -- an OrderedDict() that contains the transactions in the database with their support count\n",
    "    \"\"\"\n",
    "    categories = ['abbreviation', 'entity', 'description', 'human', 'location', 'numeric']\n",
    "    \n",
    "    ordered_item_set = {}\n",
    "\n",
    "    # Populate OrderedDict() with the categories as keys\n",
    "    for category in categories:\n",
    "        ordered_item_set[category] = 0\n",
    "    \n",
    "    for key in item_set.keys():\n",
    "        index = len(key)\n",
    "        category = key[index-1]\n",
    "        ordered_item_set[category] += 1\n",
    "        \n",
    "    return OrderedDict(sorted(ordered_item_set.items(), key=itemgetter(1), reverse=True))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_item_set = sort_frequent_item_set(transaction_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------\n",
    "### Tree Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, name, count, parent):\n",
    "        self.name = name\n",
    "        self.count = count\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        self.node_link = None\n",
    "        \n",
    "    # get the child of this node with the name 'name'\n",
    "    def get_child(self, name):\n",
    "        for c in self.children:\n",
    "            if c.name == name:\n",
    "                return c\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    #increments the count variable with a given amount    \n",
    "    def increment(self, num_occur):\n",
    "        self.count += num_occur\n",
    "        \n",
    "    def display(self, node, depth=0):\n",
    "        children = node.children\n",
    "        if depth == 0:\n",
    "            print(node.name)\n",
    "        else:\n",
    "            print(\"+\"*depth, node.name)\n",
    "\n",
    "        depth += 1\n",
    "        for child in children:\n",
    "            self.display(child, depth)  # recursive call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = Node('f', 1, None)\n",
    "a = Node('a', 2, None)\n",
    "y = Node('y', 3, None)\n",
    "f.children.append(a)\n",
    "f.children.append(y)\n",
    "f.children[0].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes the node in the header table with the specified label and add the target node in the end of th chained nodes linked together by the property `node_link` in each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_header_table(head_node, target_node):\n",
    "    \"\"\"Attach the target node to end of the linked list.\"\"\"\n",
    "    \n",
    "    # Do not use recursion to traverse a linked list!\n",
    "    while (head_node.node_link != None): \n",
    "        head_node = head_node.node_link\n",
    "    \n",
    "    head_node.node_link = target_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of **count a node** has is the total number of its appearance in the whole dataset. This is why **node count** in this function is incremented by the **count of the pattern**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grow(items, node, header_table, count):\n",
    "    \"\"\"\n",
    "    Adds a branch in the tree if it does not exist using the sequence given in items.\n",
    "    \"\"\"\n",
    "\n",
    "    # if a node already exist in the tree, increments its\n",
    "    # count by the number of times the pattern occurs\n",
    "    if node.get_child(items[0]) != None:\n",
    "        node.get_child(items[0]).increment(count)\n",
    "    # if the node does not exist, grow the tree\n",
    "    else:\n",
    "        new_tree_node = Node(items[0], count, node)\n",
    "        node.children.append(new_tree_node)\n",
    "\n",
    "        if items[0] in header_table.keys():\n",
    "            if header_table[items[0]] == None:\n",
    "                header_table[items[0]] = new_tree_node\n",
    "            else:\n",
    "                update_header_table(header_table[items[0]], node.children[len(node.children)-1])\n",
    "\n",
    "    if len(items) > 1:\n",
    "        grow(items[1::], node.get_child(items[0]), header_table, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **header_table** is a dictionary that has the category as the key. The value of each key is a list of links to category nodes (nodes with names that are in category).\n",
    "\n",
    "The dataset in the form of `OrderedDict([((<q-word>, <pos-tags>, <category>), <count>)])` where **q-word** is the question word, **pos-tags** is the series of part-of-speech tags the sentence has, **category** is the label of the question and the **count** is the number of occurance of the data in the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(dataset):\n",
    "    \"\"\"Takes the dataset as an arguments and builds the tree.\n",
    "    This makes two passes through the dataset. \n",
    "    The first pass goes through everything in the dataset and counts \n",
    "    the frequency of each term. These are stored in the header table.\"\"\"\n",
    "    # holds the list of categories and the link to the nodes associated to them\n",
    "    header_table = {\n",
    "        \"abbreviation\": None,\n",
    "        \"description\": None,\n",
    "        \"entity\": None,\n",
    "        \"human\": None,\n",
    "        \"location\": None,\n",
    "        \"numeric\": None,\n",
    "    }\n",
    "\n",
    "    # initialize the tree with the root node\n",
    "    tree = Node('Root', 1, None)\n",
    "    \n",
    "    for transaction, count in dataset.items():\n",
    "        items = list(transaction)\n",
    "        grow(items, tree, header_table, count)\n",
    "    \n",
    "    return tree, header_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree, header_table = build(transaction_set)\n",
    "start = tree.get_child(\"saan\")\n",
    "# tree.display(start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------\n",
    "### Debbuging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity 243\n",
      "human 235\n",
      "location 153\n",
      "description 586\n",
      "numeric 141\n",
      "abbreviation 7\n"
     ]
    }
   ],
   "source": [
    "for key in header_table:\n",
    "    count = 0\n",
    "    node = header_table[key]\n",
    "    while node != None:\n",
    "        count += 1\n",
    "        node = node.node_link\n",
    "    print(key, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------\n",
    "### Mining Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a leaf node (this is the node that contains the category in our tree), this method will gather all the node_links a category has. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leaf_node comes from header table\n",
    "def find_postfix_path(leaf_node):\n",
    "    \"\"\"This function iterates through the linked list until it hits \n",
    "    the end. For each item it encounters, it calls ascendTreeV2().\n",
    "    This list is returned and added to the conditional category base \n",
    "    dictionary called condPats.\"\"\"\n",
    "    \n",
    "    # list of all the paths with each category\n",
    "    conditional_patterns = []\n",
    "\n",
    "    while leaf_node != None:\n",
    "        postfix_path = []\n",
    "        ascend_path(leaf_node, postfix_path)\n",
    "        conditional_patterns.append(\n",
    "            list(reversed(list(postfix_path[1:])))\n",
    "        )\n",
    "\n",
    "        leaf_node = leaf_node.node_link\n",
    "\n",
    "    return conditional_patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the method that will asccend the tree-structure and gather all the nodes in the path of the given cateogry node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ascend_path(leaf_node, postfix_path):\n",
    "    \"\"\" Ascends from leaf node to root, collecting the names of \n",
    "    items it encounters\"\"\"\n",
    "\n",
    "    if leaf_node.parent != None:\n",
    "        postfix_path.append((leaf_node.name, leaf_node.count,))\n",
    "        ascend_path(leaf_node.parent, postfix_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key of the **header_table** is the category. The value of each key is a node which is linked to other nodes that contains the said category. This will help us gather all the paths in the tree that belongs to that category.\n",
    "\n",
    "In FP-growth, **header_table** contains all of the frequent items found in the dataset in order to gather all the paths in which an item *x* occurs. However, in this algorithm we are only interested in gathering all the paths that has the same category that is why the **header_table** keys are categories.\n",
    "\n",
    "Another thing, in FP-growth, a node is eliminated alone if its count did not reach the **minimum support** count. We did not do that in this algorithm because one of the arguments being proven is that order of the sentence matters. The removal of that single node will destroy the order of the sentence. That is why instead of singly eliminating a node, the whole path in which that node belong will not qualify to be a part of the final conditional pattern bases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mine_rules(header_table, minimum_support):\n",
    "    mined_rules = []\n",
    "    \n",
    "    for key in header_table:\n",
    "        # Conditional Pattern Bases\n",
    "        cpb = find_postfix_path(header_table[key])\n",
    "\n",
    "        # Conditional Frequent Pattern tree\n",
    "        cft = []\n",
    "\n",
    "        for index in range(0, len(cpb)):\n",
    "            for item in range(0, len(cpb[index])):\n",
    "                # Removes the path that did not reach the minimum support\n",
    "                if cpb[index][item][1] < minimum_support:\n",
    "                    break\n",
    "                elif item == len(cpb[index])-1:\n",
    "                    cft.append(cpb[index])\n",
    "\n",
    "        print(\"Key: \", key, len(cft))\n",
    "        print(\"Conditional FP-Tree: \", cft)\n",
    "\n",
    "        value = []\n",
    "\n",
    "        for category in cft:\n",
    "            element = tuple(t[0] for t in category)\n",
    "            value.append(element)\n",
    "\n",
    "        mined_rules.append([key, value])\n",
    "        \n",
    "    return mined_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key:  entity 1\n",
      "Conditional FP-Tree:  [[('paano', 356), ('pr', 151), ('vb', 86)]]\n",
      "Key:  human 2\n",
      "Conditional FP-Tree:  [[('paano', 356), ('pr', 151), ('vb', 86)], [('sino', 342), ('dt', 221), ('vb', 116)]]\n",
      "Key:  location 2\n",
      "Conditional FP-Tree:  [[('saan', 351), ('pr', 202), ('vb', 124)], [('saan', 351), ('pr', 202)]]\n",
      "Key:  description 5\n",
      "Conditional FP-Tree:  [[('paano', 356), ('pr', 151), ('vb', 86)], [('saan', 351), ('pr', 202), ('vb', 124)], [('ano', 321), ('dt', 244), ('nn', 114)], [('paano', 356), ('rb', 190)], [('kailan', 346), ('pr', 188), ('vb', 96)]]\n",
      "Key:  numeric 2\n",
      "Conditional FP-Tree:  [[('saan', 351), ('pr', 202), ('vb', 124)], [('kailan', 346), ('pr', 188), ('vb', 96)]]\n",
      "Key:  abbreviation 1\n",
      "Conditional FP-Tree:  [[('saan', 351), ('pr', 202), ('vb', 124)]]\n"
     ]
    }
   ],
   "source": [
    "# 80 is the minimum number of occurances of a pattern (?)\n",
    "rules = mine_rules(header_table, 80)\n",
    "# rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------\n",
    "### Conflict Resolution Schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_subset(rule, pattern):\n",
    "    r = list(rule)\n",
    "    p = list(pattern)\n",
    "    \n",
    "    if len(r) > len(p):\n",
    "        return False\n",
    "    else:\n",
    "        l = p[:len(r)]\n",
    "        if r == l:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ordered_rule_set(training_data, rules):\n",
    "    \"\"\"Rank all of the mined rules according to their accuracy.\n",
    "    Form of both data: ((pattern), category)\n",
    "    Returns the oredered rule set as an array of tuples in the\n",
    "    form (((pattern), category), accuracy).\n",
    "    \"\"\"\n",
    "\n",
    "    antecedent_counts = {} # no. of occurances of the antecedent\n",
    "    antConseqCounts = {} # no. of antecedent that matches with the consequent\n",
    "    \n",
    "    for rule in rules: # populate dictionaries\n",
    "        for pattern in rule[1]:\n",
    "            antecedent_counts[pattern] = 0\n",
    "            antConseqCounts[(pattern, rule[0])] = 0\n",
    "    \n",
    "    # Counts the number of antecedent in training data\n",
    "    for data in training_data: \n",
    "        if data[0] in antecedent_counts.keys():\n",
    "            antecedent_counts[data[0]] += 1\n",
    "            \n",
    "#     print \"Antecedent Count Dictionary:\\n\", antecedent_counts\n",
    "\n",
    "    # Counts the number of antecedent that matches with the consequent in training data\n",
    "    for data in training_data:\n",
    "        if data in antConseqCounts.keys():\n",
    "            antConseqCounts[data] += 1\n",
    "#     print(antConseqCounts)\n",
    "            \n",
    "#     print \"Antecendent Consequence:\\n\", antConseqCounts\n",
    "    \n",
    "    orderedRuleSet = []\n",
    "    for rule in antConseqCounts:\n",
    "        accuracy = (float(antConseqCounts[rule])/\n",
    "                    float(antecedent_counts[rule[0]]))*100\n",
    "        accuracy = int(accuracy)\n",
    "        orderedRuleSet.append((rule, accuracy,))\n",
    "        \n",
    "    orderedRuleSet = sorted(orderedRuleSet, key=lambda rule: rule[1], \n",
    "                            reverse=True)\n",
    "    print(\"Ordered Rule Set:\\n\", orderedRuleSet)\n",
    "    \n",
    "    return orderedRuleSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_class(test_data):\n",
    "    \"\"\"Data form: ((pattern), category)\"\"\"\n",
    "    \n",
    "    question_word = {'alin': 'entity', 'saan':'location', 'ano':'entity', \n",
    "                 'kailan':'numeric', 'paano':'description', \n",
    "                 'sino':'human', 'bakit':'description'}\n",
    "    \n",
    "    for key in question_word.keys():\n",
    "        if key in test_data[0]:\n",
    "            return question_word[key]\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------\n",
    "### Classification and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(testing, rules, decision_list):\n",
    "    \"\"\"testing data form: ((pattern), category)\n",
    "    rules form: [['category', [(pattern1), (pattern2)]]]\n",
    "    decision_list form: [(((pattern), 'category'), accuracy)]\"\"\"\n",
    "    \n",
    "    table = []\n",
    "    \n",
    "    for data in testing: # populate table\n",
    "        row = []\n",
    "        row.append(data[0])\n",
    "        \n",
    "        category = []\n",
    "        for rule in rules: # question classification\n",
    "            for pattern in rule[1]:\n",
    "                if data[0] == pattern:\n",
    "                    category.append(rule[0])\n",
    "        \n",
    "        # Conflict Resolution:\n",
    "        # - if sentence structure did not trigger any category\n",
    "        if len(category) == 0:\n",
    "            for i in range(0, len(rules)): # for each category\n",
    "                for j in range(0, len(rules[i][1])): # for each pattern in that category \n",
    "                    # check if any rule is a subset of a sentence\n",
    "                    if is_subset(rules[i][1][j], data[0]) == True:\n",
    "                        category.append(rules[i][0])\n",
    "                        break\n",
    "                    # if testing data still didn't trigger any rule\n",
    "                    # assign default class according to its question word\n",
    "                    elif  (is_subset(rules[i][1][j], data[0])==False) and (i == len(rules)-1) and (j == len(rules[i][1])-1):\n",
    "                            default = get_default_class(data[0])\n",
    "                            if default != None:\n",
    "                                category.append(default)\n",
    "                                break\n",
    "            \n",
    "            # - more than one category was triggered by the subset\n",
    "            if len(category)>1:\n",
    "                default = get_default_class(data[0])\n",
    "                if default != None:\n",
    "                    category = []\n",
    "                    category.append(default)\n",
    "\n",
    "# For debugging purposes:                  \n",
    "#             if len(category) > 1:\n",
    "#                 print(\"category=0: \")\n",
    "        # - if sentence structure triggered many category\n",
    "        elif len(category) > 1:\n",
    "            ranks = []\n",
    "            # for each category triggered by data\n",
    "            for i in range(0, len(category)): \n",
    "                # combine data pattern with category as tuples\n",
    "                tmpD = (data[0], category[i],) \n",
    "                \n",
    "                # for each rule in decision_list\n",
    "                for rule in decision_list:\n",
    "                    # if combined pattern and category match rule[i]\n",
    "                    if tmpD == rule[0]: \n",
    "                        # get the index\n",
    "                        ranks.append(decision_list.index(rule))\n",
    "#                         print ranks\n",
    "            \n",
    "            new_category = []\n",
    "            new_category.append(category[ranks.index(max(ranks))])\n",
    "            category = new_category\n",
    "            \n",
    "# For debugging purpose:                  \n",
    "#             if len(category):\n",
    "#                 print \"category=1: \", data[0], category\n",
    "            \n",
    "        row.append(category)\n",
    "        table.append(row)\n",
    "    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_testing_set(testing_set):\n",
    "    final_set = []\n",
    "    \n",
    "    for data in testing_set:\n",
    "        key = tuple(data[:len(data)-2])\n",
    "        value = data[len(data)-1]\n",
    "        final_set.append((key,value,))\n",
    "    \n",
    "    return final_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_training_set(training_set):\n",
    "    \"\"\"training set form: ['anong', 'jj', 'pr', 'vb', 'cc', \n",
    "    'vb', 'pr', 'cc', 'pr', 'dt', 'vb', 'pr', 'description']\n",
    "    Returns final_set in the form: ((pattern), category)\"\"\"\n",
    "    \n",
    "    final_set = []\n",
    "    \n",
    "    for data in training_set:\n",
    "        lst = list(data)\n",
    "        pattern = tuple(lst[:len(lst)-1])\n",
    "        category = lst[len(lst)-1]\n",
    "        final_set.append((pattern, category,))\n",
    "            \n",
    "    return final_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "612"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data = initialize_testing_set(raw_testing)\n",
    "len(testing_data)\n",
    "training_data = initialize_training_set(raw_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordered Rule Set:\n",
      " [((('saan', 'pr'), 'location'), 100), ((('sino', 'dt', 'vb'), 'human'), 100), ((('ano', 'dt', 'nn'), 'description'), 100), ((('paano', 'rb'), 'description'), 100), ((('paano', 'pr', 'vb'), 'description'), 86), ((('kailan', 'pr', 'vb'), 'numeric'), 75), ((('saan', 'pr', 'vb'), 'location'), 73), ((('kailan', 'pr', 'vb'), 'description'), 24), ((('saan', 'pr', 'vb'), 'description'), 20), ((('paano', 'pr', 'vb'), 'human'), 6), ((('paano', 'pr', 'vb'), 'entity'), 6), ((('saan', 'pr', 'vb'), 'abbreviation'), 3), ((('saan', 'pr', 'vb'), 'numeric'), 2)]\n"
     ]
    }
   ],
   "source": [
    "decision_list = get_ordered_rule_set(training_data, rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_table = classify(testing_data, rules, decision_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------\n",
    "### Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comparison_table(testing_data, table):\n",
    "    performance = []\n",
    "    \n",
    "    for i in range(0, len(testing_data)):\n",
    "        row = []\n",
    "        row.append(testing_data[i][1])\n",
    "        row.append(table[i][1])\n",
    "        performance.append(row)\n",
    "    \n",
    "#     print(performance)\n",
    "    \n",
    "    correct = 0\n",
    "    misclassified = 0\n",
    "    unclassified = 0\n",
    "    multiple_category = 0\n",
    "    \n",
    "    for item in performance:\n",
    "        if len(item[1]) > 1:\n",
    "            multiple_category += 1\n",
    "        else:\n",
    "            if item[0] == item[1][0]:\n",
    "                correct += 1\n",
    "            elif len(item[1]) == 0:\n",
    "                unclassified += 1\n",
    "            elif item[0] != item[1][0]:\n",
    "                misclassified += 1\n",
    "            \n",
    "    print(\"Total number of testing data: {}\".format(len(testing_data)))\n",
    "    print(\"Correctly classified items: {}\".format(correct))\n",
    "    print(\"Misclassified items: {}\".format(misclassified))\n",
    "    print(\"Unclassified items: {}\".format(unclassified))\n",
    "    print(\"Multiple Classified items: {}\".format(multiple_category))\n",
    "    \n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of testing data: 612\n",
      "Correctly classified items: 495\n",
      "Misclassified items: 117\n",
      "Unclassified items: 0\n",
      "Multiple Classified items: 0\n"
     ]
    }
   ],
   "source": [
    "comparison = get_comparison_table(testing_data, prediction_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faienix/.virtualenvs/classification/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.69117069395711084, 0.72872214307720551, 0.69513440580362929, None)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['abbreviation', 'entity', 'description', 'human', \n",
    "            'location', 'numeric']\n",
    "y_category = []\n",
    "y_pred = []\n",
    "\n",
    "for row in comparison:\n",
    "    y_category.append(row[0])\n",
    "    y_pred.append(row[1][0])\n",
    "\n",
    "precision_recall_fscore_support(y_category, y_pred, labels=numpy.unique(categories), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faienix/.virtualenvs/classification/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.78082192,  0.72857143,  0.83333333,  0.96732026,\n",
       "        0.86075949])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate f-score for each category\n",
    "f1_score(y_category,y_pred, labels=numpy.unique(categories), average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faienix/.virtualenvs/classification/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.80947834019097276"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate f-score of the classifier\n",
    "f1_score(y_category, y_pred, average='weighted', labels=numpy.unique(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   3,   0,   0,   0],\n",
       "       [  0, 171,  57,  13,   1,  17],\n",
       "       [  0,   0, 102,   1,   0,   0],\n",
       "       [  0,   4,  13,  80,   1,   0],\n",
       "       [  0,   0,   2,   0,  74,   1],\n",
       "       [  0,   4,   0,   0,   0,  68]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# row : actual :: column : predicted \n",
    "confusion_matrix(y_category, y_pred, labels=numpy.unique(categories))\n",
    "# I do not understand this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
